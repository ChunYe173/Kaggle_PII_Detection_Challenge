{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from tokenizers import AddedToken\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_no_pii(example, percent_allow=0.2):\n",
    "    # Return True if there is PII\n",
    "    # Or 20% of the time if there isn't\n",
    "    # To remove 80% of entry that only has \"O\" in the labels\n",
    "    import random\n",
    "    has_pii = set(\"O\") != set(example[\"provided_labels\"])\n",
    "\n",
    "    return has_pii or (random.random() < percent_allow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "    import numpy as np\n",
    "    from tokenizers import AddedToken\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n",
    "\n",
    "        text.append(t)\n",
    "        labels.extend([l]*len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        while start_idx >= len(labels):\n",
    "            start_idx -= 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"labels\": token_labels,\n",
    "        \"length\": length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, tokenizer, label2id, max_length):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True, max_length=max_length)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"provided_labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                print(word_idx)\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, metric, all_labels):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    metric = evaluate.load(\"seqeval\")\\n\\n    model = AutoModelForTokenClassification.from_pretrained(training_model_path, num_labels=len(all_labels), id2label=id2label, label2id=label2id)\\n    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\\n\\n    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\\n\\n\\n    ### All possible training arguments that may be defined in may be found here: (To-explore)\\n    # https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py\\n    args = TrainingArguments(\\n        \"output\",\\n        fp16=False,\\n        learning_rate=5e-5,\\n        weight_decay=0.01,\\n        warmup_ratio=0.1,\\n        per_device_train_batch_size=8,\\n        per_device_eval_batch_size=4,\\n        report_to=\"none\",\\n        evaluation_strategy=\"epoch\",\\n        save_strategy=\"epoch\",\\n        save_total_limit=1,\\n        logging_steps=5,\\n        metric_for_best_model=\"overall_recall\",\\n        greater_is_better=True,\\n        gradient_checkpointing=True,\\n        num_train_epochs=1,\\n        dataloader_num_workers=1,\\n    )\\n\\n    # may want to try to balance classes in splits\\n    final_ds = ds.train_test_split(test_size=0.2)\\n\\n    trainer = Trainer(\\n        model=model,\\n        args=args,\\n        train_dataset=final_ds[\"train\"],\\n        eval_dataset=final_ds[\"test\"],\\n        data_collator=collator,\\n        tokenizer=tokenizer,\\n        compute_metrics=partial(compute_metrics, metric=metric, all_labels=all_labels),\\n    )\\n\\n    print(\"Before training\")\\n    trainer.train()\\n    trainer.save_model(model_save_path) # saves tokenizer with model\\n    trainer.save_state()\\n    return # move the return according to line by line verification progress in this script'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(training, training_model_path, training_max_length, path_to_datasets, model_save_path):\n",
    "    data = []\n",
    "    for dataset in path_to_datasets:\n",
    "      data.extend(json.load(open(dataset)))\n",
    "\n",
    "    print(type(data)) # == list\n",
    "    print(type(data[0])) # == dict\n",
    "    print((data[0]))\n",
    "    print((data[1]))\n",
    "    print((data[2]))\n",
    "\n",
    "    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "    label2id = {l: i for i,l in enumerate(all_labels)}\n",
    "    id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "    ds = Dataset.from_dict({\n",
    "        \"full_text\": [x[\"full_text\"] for x in data],\n",
    "        \"document\": [x[\"document\"] for x in data],\n",
    "        \"tokens\": [x[\"tokens\"] for x in data],\n",
    "        \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "        \"provided_labels\": [x[\"labels\"] for x in data] #,b 0.576\n",
    "    })\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(training_model_path)\n",
    "\n",
    "    # lots of newlines in the text\n",
    "    # adding this should be helpful\n",
    "    tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n",
    "\n",
    "    ds = ds.filter(\n",
    "        filter_no_pii,\n",
    "        num_proc=2,\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        tokenize_and_align_labels,\n",
    "        fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": training_max_length},\n",
    "        num_proc=2,\n",
    "    )\n",
    "\n",
    "    metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(training_model_path, num_labels=len(all_labels), id2label=id2label, label2id=label2id)\n",
    "    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "\n",
    "    ### All possible training arguments that may be defined in may be found here: (To-explore)\n",
    "    # https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py\n",
    "    args = TrainingArguments(\n",
    "        \"output\",\n",
    "        fp16=False,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        logging_steps=5,\n",
    "        metric_for_best_model=\"overall_recall\",\n",
    "        greater_is_better=True,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs=1,\n",
    "        dataloader_num_workers=1,\n",
    "    )\n",
    "\n",
    "    # may want to try to balance classes in splits\n",
    "    final_ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=final_ds[\"train\"],\n",
    "        eval_dataset=final_ds[\"test\"],\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=partial(compute_metrics, metric=metric, all_labels=all_labels),\n",
    "    )\n",
    "\n",
    "    print(\"Before training\")\n",
    "    trainer.train()\n",
    "    trainer.save_model(model_save_path) # saves tokenizer with model\n",
    "    trainer.save_state()\n",
    "    return # move the return according to line by line verification progress in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "{'document': 7, 'full_text': \"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\\n\\nThis tool has many advantages:\\n\\n•  It is accessible to all and does not require significant material investment and can be done  quickly\\n\\n•  It is scalable\\n\\n•  It allows categorization and linking of information\\n\\n•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\\n\\n•  It is suitable for all people and is easy to learn\\n\\n•  It is fun and encourages exchanges\\n\\n•  It makes visible the dimension of projects, opportunities, interconnections\\n\\n•  It synthesizes\\n\\n•  It makes the project understandable\\n\\n•  It allows you to explore ideas\\n\\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\\n\\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\\n\\nCreativity is enhanced because participants feel comfortable with the method.\\n\\nApplication & Insight\\n\\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\\n\\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\\n\\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\\n\\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\\n\\nApproach\\n\\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAnnex 1: Mind Map Shared facilities project\\n\\n\", 'tokens': ['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Challenge', '&', 'selection', '\\n\\n', 'The', 'tool', 'I', 'use', 'to', 'help', 'all', 'stakeholders', 'finding', 'their', 'way', 'through', 'the', 'complexity', 'of', 'a', 'project', 'is', 'the', ' ', 'mind', 'map', '.', '\\n\\n', 'What', 'exactly', 'is', 'a', 'mind', 'map', '?', 'According', 'to', 'the', 'definition', 'of', 'Buzan', 'T.', 'and', 'Buzan', 'B.', '(', '1999', ',', 'Dessine', '-', 'moi', ' ', \"l'intelligence\", '.', 'Paris', ':', 'Les', 'Éditions', \"d'Organisation\", '.', ')', ',', 'the', 'mind', 'map', '(', 'or', 'heuristic', 'diagram', ')', 'is', 'a', 'graphic', ' ', 'representation', 'technique', 'that', 'follows', 'the', 'natural', 'functioning', 'of', 'the', 'mind', 'and', 'allows', 'the', 'brain', \"'s\", ' ', 'potential', 'to', 'be', 'released', '.', 'Cf', 'Annex1', '\\n\\n', 'This', 'tool', 'has', 'many', 'advantages', ':', '\\n\\n', '•', ' ', 'It', 'is', 'accessible', 'to', 'all', 'and', 'does', 'not', 'require', 'significant', 'material', 'investment', 'and', 'can', 'be', 'done', ' ', 'quickly', '\\n\\n', '•', ' ', 'It', 'is', 'scalable', '\\n\\n', '•', ' ', 'It', 'allows', 'categorization', 'and', 'linking', 'of', 'information', '\\n\\n', '•', ' ', 'It', 'can', 'be', 'applied', 'to', 'any', 'type', 'of', 'situation', ':', 'notetaking', ',', 'problem', 'solving', ',', 'analysis', ',', 'creation', 'of', ' ', 'new', 'ideas', '\\n\\n', '•', ' ', 'It', 'is', 'suitable', 'for', 'all', 'people', 'and', 'is', 'easy', 'to', 'learn', '\\n\\n', '•', ' ', 'It', 'is', 'fun', 'and', 'encourages', 'exchanges', '\\n\\n', '•', ' ', 'It', 'makes', 'visible', 'the', 'dimension', 'of', 'projects', ',', 'opportunities', ',', 'interconnections', '\\n\\n', '•', ' ', 'It', 'synthesizes', '\\n\\n', '•', ' ', 'It', 'makes', 'the', 'project', 'understandable', '\\n\\n', '•', ' ', 'It', 'allows', 'you', 'to', 'explore', 'ideas', '\\n\\n', 'The', 'creation', 'of', 'a', 'mind', 'map', 'starts', 'with', 'an', 'idea', '/', 'problem', 'located', 'at', 'its', 'center', '.', 'This', 'starting', 'point', ' ', 'generates', 'ideas', '/', 'work', 'areas', ',', 'incremented', 'around', 'this', 'center', 'in', 'a', 'radial', 'structure', ',', 'which', 'in', 'turn', 'is', ' ', 'completed', 'with', 'as', 'many', 'branches', 'as', 'new', 'ideas', '.', '\\n\\n', 'This', 'tool', 'enables', 'creativity', 'and', 'logic', 'to', 'be', 'mobilized', ',', 'it', 'is', 'a', 'map', 'of', 'the', 'thoughts', '.', '\\n\\n', 'Creativity', 'is', 'enhanced', 'because', 'participants', 'feel', 'comfortable', 'with', 'the', 'method', '.', '\\n\\n', 'Application', '&', 'Insight', '\\n\\n', 'I', 'start', 'the', 'process', 'of', 'the', 'mind', 'map', 'creation', 'with', 'the', 'stakeholders', 'standing', 'around', 'a', 'large', 'board', ' ', '(', 'white', 'or', 'paper', 'board', ')', '.', 'In', 'the', 'center', 'of', 'the', 'board', ',', 'I', 'write', 'and', 'highlight', 'the', 'topic', 'to', 'design', '.', '\\n\\n', 'Through', 'a', 'series', 'of', 'questions', ',', 'I', 'guide', 'the', 'stakeholders', 'in', 'modelling', 'the', 'mind', 'map', '.', 'I', 'adapt', 'the', 'series', ' ', 'of', 'questions', 'according', 'to', 'the', 'topic', 'to', 'be', 'addressed', '.', 'In', 'the', 'type', 'of', 'questions', ',', 'we', 'can', 'use', ':', 'who', ',', 'what', ',', ' ', 'when', ',', 'where', ',', 'why', ',', 'how', ',', 'how', 'much', '.', '\\n\\n', 'The', 'use', 'of', 'the', '“', 'why', '”', 'is', 'very', 'interesting', 'to', 'understand', 'the', 'origin', '.', 'By', 'this', 'way', ',', 'the', 'interviewed', 'person', ' ', 'frees', 'itself', 'from', 'paradigms', 'and', 'thus', 'dares', 'to', 'propose', 'new', 'ideas', '/', 'ways', 'of', 'functioning', '.', 'I', 'plan', 'two', ' ', 'hours', 'for', 'a', 'workshop', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'After', 'modelling', 'the', 'mind', 'map', 'on', 'paper', ',', 'I', 'propose', 'to', 'the', 'participants', 'a', 'digital', 'visualization', 'of', 'their', ' ', 'work', 'with', 'the', 'addition', 'of', 'color', 'codes', ',', 'images', 'and', 'interconnections', '.', 'This', 'second', 'workshop', 'also', 'lasts', ' ', 'two', 'hours', 'and', 'allows', 'the', 'mind', 'map', 'to', 'evolve', '.', 'Once', 'familiarized', 'with', 'it', ',', 'the', 'stakeholders', 'discover', ' ', 'the', 'power', 'of', 'the', 'tool', '.', 'Then', ',', 'the', 'second', 'workshop', 'brings', 'out', 'even', 'more', 'ideas', 'and', 'constructive', ' ', 'exchanges', 'between', 'the', 'stakeholders', '.', 'Around', 'this', 'new', 'mind', 'map', ',', 'they', 'have', 'learned', 'to', 'work', ' ', 'together', 'and', 'want', 'to', 'make', 'visible', 'the', 'untold', 'ideas', '.', '\\n\\n', 'I', 'now', 'present', 'all', 'the', 'projects', 'I', 'manage', 'in', 'this', 'type', 'of', 'format', 'in', 'order', 'to', 'ease', 'rapid', 'understanding', 'for', ' ', 'decision', '-', 'makers', '.', 'These', 'presentations', 'are', 'the', 'core', 'of', 'my', 'business', 'models', '.', 'The', 'decision', '-', 'makers', 'are', ' ', 'thus', 'able', 'to', 'identify', 'the', 'opportunities', 'of', 'the', 'projects', 'and', 'can', 'take', 'quick', 'decisions', 'to', 'validate', 'them', '.', ' ', 'They', 'find', 'answers', 'to', 'their', 'questions', 'thank', 'to', 'a', 'schematic', 'representation', '.', '\\n\\n', 'Approach', '\\n\\n', 'What', 'I', 'find', 'amazing', 'with', 'the', 'facilitation', 'of', 'this', 'type', 'of', 'workshop', 'is', 'the', 'participants', 'commitment', 'for', ' ', 'the', 'project', '.', 'This', 'tool', 'helps', 'to', 'give', 'meaning', '.', 'The', 'participants', 'appropriate', 'the', 'story', 'and', 'want', 'to', 'keep', ' ', 'writing', 'it', '.', 'Then', ',', 'they', 'easily', 'become', 'actors', 'or', 'sponsors', 'of', 'the', 'project', '.', 'A', 'trust', 'relationship', 'is', 'built', ',', ' ', 'thus', 'facilitating', 'the', 'implementation', 'of', 'related', 'actions', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Annex', '1', ':', 'Mind', 'Map', 'Shared', 'facilities', 'project', '\\n\\n'], 'trailing_whitespace': [True, True, True, True, False, False, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, False, False, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, False, False, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, False, True, True, False, False, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, False, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, False, True, False, True, False, False, True, False, True, False, True, False, True, True, False, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, True, True, False, False], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'document': 10, 'full_text': 'Diego Estrada\\n\\nDesign Thinking Assignment\\n\\nVisualization Tool\\n\\nChallenge & Selection\\n\\nThe elderly were having a hard time adapting to the changes we brought in our bank. As  a result of a poorly implemented linear solution, a more customer centric approach was  needed.\\n\\nAfter learning about design thinking in this course, we decided to apply it to solve this  problem. The visualization tool allowed the team to create a dynamic presentation using  diagrams, figures and drawings on the go that really resonated among the stakeholders.  Previous to this change, none of our solutions seemed to be adequate for them, but the  new implementation created a different type of connection with them that helped them  understand the problem in the way the team and I did.\\n\\nApplication\\n\\nThe process starts in the prep time. The team uses a series of tools and software to  develop a presentation using the surveys gathered during research and the solutions we  created during the process. The use of graphs to quickly show statistics in a fully visual  way, rather than verbally was a game changer.\\n\\nAfter having a presentation prepared, the team hands an activity to the stakeholders,  where the solutions discussed previously appear. Nonetheless, the solutions need more  work to them. After this. The stakeholders are asked to help complete the solutions  while the team and I create diagrams on a blackboard to represent how their  suggestions would impact on this specific problem.\\n\\nThe use of a group activity strengthens the bond between the company and their  investors. It makes them feel like they take part and help solve the problems as well as  show how customer centric the solutions are. Every complaint and suggestion from  customers are read and evaluated using the graph shown in the course (Involving: can  we do it? Can we afford it? …). The finalization of this activity leaves the team and the  stakeholders on the same page. It allows them to completely understand and feel part  of the solution and also gives them the chance to ask better questions, which eases the  work of the team.\\n\\nInsight & Approach\\n\\nThe use of this method created a new workflow in the Design Team. It increased the  productivity and the success rate as well as the customer/stakeholders satisfaction. The  use of the visualization tool created an engaged group of people who work together to\\n\\nDiego Estrada\\n\\nfind a solution based on their customer satisfaction. This solution is later revised and  tweaked with the help of the stakeholders who are deeply involved in the process.\\n\\nPresentations, graphics, and activities have added a huge increase in satisfaction. As a  company we also learnt that engaging different areas can be difficult because of the  varying levels of understanding, but when paired with the adequate process things just  flow.\\n\\n(This story is fictional and was created for solving the assignment)\\n\\n', 'tokens': ['Diego', 'Estrada', '\\n\\n', 'Design', 'Thinking', 'Assignment', '\\n\\n', 'Visualization', 'Tool', '\\n\\n', 'Challenge', '&', 'Selection', '\\n\\n', 'The', 'elderly', 'were', 'having', 'a', 'hard', 'time', 'adapting', 'to', 'the', 'changes', 'we', 'brought', 'in', 'our', 'bank', '.', 'As', ' ', 'a', 'result', 'of', 'a', 'poorly', 'implemented', 'linear', 'solution', ',', 'a', 'more', 'customer', 'centric', 'approach', 'was', ' ', 'needed', '.', '\\n\\n', 'After', 'learning', 'about', 'design', 'thinking', 'in', 'this', 'course', ',', 'we', 'decided', 'to', 'apply', 'it', 'to', 'solve', 'this', ' ', 'problem', '.', 'The', 'visualization', 'tool', 'allowed', 'the', 'team', 'to', 'create', 'a', 'dynamic', 'presentation', 'using', ' ', 'diagrams', ',', 'figures', 'and', 'drawings', 'on', 'the', 'go', 'that', 'really', 'resonated', 'among', 'the', 'stakeholders', '.', ' ', 'Previous', 'to', 'this', 'change', ',', 'none', 'of', 'our', 'solutions', 'seemed', 'to', 'be', 'adequate', 'for', 'them', ',', 'but', 'the', ' ', 'new', 'implementation', 'created', 'a', 'different', 'type', 'of', 'connection', 'with', 'them', 'that', 'helped', 'them', ' ', 'understand', 'the', 'problem', 'in', 'the', 'way', 'the', 'team', 'and', 'I', 'did', '.', '\\n\\n', 'Application', '\\n\\n', 'The', 'process', 'starts', 'in', 'the', 'prep', 'time', '.', 'The', 'team', 'uses', 'a', 'series', 'of', 'tools', 'and', 'software', 'to', ' ', 'develop', 'a', 'presentation', 'using', 'the', 'surveys', 'gathered', 'during', 'research', 'and', 'the', 'solutions', 'we', ' ', 'created', 'during', 'the', 'process', '.', 'The', 'use', 'of', 'graphs', 'to', 'quickly', 'show', 'statistics', 'in', 'a', 'fully', 'visual', ' ', 'way', ',', 'rather', 'than', 'verbally', 'was', 'a', 'game', 'changer', '.', '\\n\\n', 'After', 'having', 'a', 'presentation', 'prepared', ',', 'the', 'team', 'hands', 'an', 'activity', 'to', 'the', 'stakeholders', ',', ' ', 'where', 'the', 'solutions', 'discussed', 'previously', 'appear', '.', 'Nonetheless', ',', 'the', 'solutions', 'need', 'more', ' ', 'work', 'to', 'them', '.', 'After', 'this', '.', 'The', 'stakeholders', 'are', 'asked', 'to', 'help', 'complete', 'the', 'solutions', ' ', 'while', 'the', 'team', 'and', 'I', 'create', 'diagrams', 'on', 'a', 'blackboard', 'to', 'represent', 'how', 'their', ' ', 'suggestions', 'would', 'impact', 'on', 'this', 'specific', 'problem', '.', '\\n\\n', 'The', 'use', 'of', 'a', 'group', 'activity', 'strengthens', 'the', 'bond', 'between', 'the', 'company', 'and', 'their', ' ', 'investors', '.', 'It', 'makes', 'them', 'feel', 'like', 'they', 'take', 'part', 'and', 'help', 'solve', 'the', 'problems', 'as', 'well', 'as', ' ', 'show', 'how', 'customer', 'centric', 'the', 'solutions', 'are', '.', 'Every', 'complaint', 'and', 'suggestion', 'from', ' ', 'customers', 'are', 'read', 'and', 'evaluated', 'using', 'the', 'graph', 'shown', 'in', 'the', 'course', '(', 'Involving', ':', 'can', ' ', 'we', 'do', 'it', '?', 'Can', 'we', 'afford', 'it', '?', '…', ')', '.', 'The', 'finalization', 'of', 'this', 'activity', 'leaves', 'the', 'team', 'and', 'the', ' ', 'stakeholders', 'on', 'the', 'same', 'page', '.', 'It', 'allows', 'them', 'to', 'completely', 'understand', 'and', 'feel', 'part', ' ', 'of', 'the', 'solution', 'and', 'also', 'gives', 'them', 'the', 'chance', 'to', 'ask', 'better', 'questions', ',', 'which', 'eases', 'the', ' ', 'work', 'of', 'the', 'team', '.', '\\n\\n', 'Insight', '&', 'Approach', '\\n\\n', 'The', 'use', 'of', 'this', 'method', 'created', 'a', 'new', 'workflow', 'in', 'the', 'Design', 'Team', '.', 'It', 'increased', 'the', ' ', 'productivity', 'and', 'the', 'success', 'rate', 'as', 'well', 'as', 'the', 'customer', '/', 'stakeholders', 'satisfaction', '.', 'The', ' ', 'use', 'of', 'the', 'visualization', 'tool', 'created', 'an', 'engaged', 'group', 'of', 'people', 'who', 'work', 'together', 'to', '\\n\\n', 'Diego', 'Estrada', '\\n\\n', 'find', 'a', 'solution', 'based', 'on', 'their', 'customer', 'satisfaction', '.', 'This', 'solution', 'is', 'later', 'revised', 'and', ' ', 'tweaked', 'with', 'the', 'help', 'of', 'the', 'stakeholders', 'who', 'are', 'deeply', 'involved', 'in', 'the', 'process', '.', '\\n\\n', 'Presentations', ',', 'graphics', ',', 'and', 'activities', 'have', 'added', 'a', 'huge', 'increase', 'in', 'satisfaction', '.', 'As', 'a', ' ', 'company', 'we', 'also', 'learnt', 'that', 'engaging', 'different', 'areas', 'can', 'be', 'difficult', 'because', 'of', 'the', ' ', 'varying', 'levels', 'of', 'understanding', ',', 'but', 'when', 'paired', 'with', 'the', 'adequate', 'process', 'things', 'just', ' ', 'flow', '.', '\\n\\n', '(', 'This', 'story', 'is', 'fictional', 'and', 'was', 'created', 'for', 'solving', 'the', 'assignment', ')', '\\n\\n'], 'trailing_whitespace': [True, False, False, True, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, False, True, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, False, True, True, False, True, True, True, True, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False], 'labels': ['B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'document': 16, 'full_text': 'Reporting process\\n\\nby Gilberto Gamboa\\n\\nChallenge\\n\\nI received a promotion of being the Regional Controller, along with my actual position of\\n\\nCountry CFO. The main responsibility of this new position was to weekly report the results\\n\\nfor the week and estimate the final results of the month of 4 countries and consolidated\\n\\nthose.\\n\\nWhen I was receiving the position, I went to visit my colleague, former Regional Controller,\\n\\nwho was promoted to Country CEO and now had interest conflicts of being the controller.\\n\\nThe process to consolidate the information of the 4 countries was that the country controllers\\n\\nsent him an email with the main figures for the week, he forwarded those to his country\\n\\naccountant who consolidated it, the accountant sent him the consolidated report and he\\n\\nfinally reported to the headquarters. The whole process took almost a full business day to\\n\\ncomplete.\\n\\nGiven that my responsibilities as Country CFO demanded more attention because my\\n\\ncountry had more operations, I decided to change the process in order to reduce the\\n\\nduration and to ensure standardization in the format, and actually, reduce the human\\n\\nintervention, making that the country controllers work directly in the consolidation file.\\n\\nSelection\\n\\nHaving in mind that there was a different kind of users of file, I select some of those to\\n\\ndetermine what was the main important things to take into account in the moment of the\\n\\nprocess of the information and the reading of the same. In that sense, we form a group of\\n\\nthe country controllers, country CEOs, IT guys, and people from the headquarters to find the\\n\\nbest solutions possible.\\n\\nApplication\\n\\nFor the first lunch, we focused on the consolidation process in order to avoid the copy-paste\\n\\nprocesses and reducing the manual intervention so, we build an online application where all\\n\\nthe controllers fill the figure of their respective country, along with the comments. During the\\n\\nfirst week of the first stage, we sent the new report along with the old one, and after the\\n\\nmeeting with the headquarters team, we ask for a post-meeting review of the new format, all\\n\\nthe assistants provided their comments and suggestions that were the input for the next\\n\\nreport.\\n\\nFor the second lunch, we focused on the feedback received from the assistants to the review\\n\\nmeeting, we adjust the report and we were able to eliminate the old one. The final report\\n\\nincluded all the suggestions received but the best of all is that reduced the time investment\\n\\nfrom about 36 men hours to around 8, without missing any valuable information and\\n\\nincluding new data that the stakeholders appreciated so much.\\n\\nInsight\\n\\nWith the application of the learning launch tool, the controller’s team along with the main\\n\\nstakeholders identified different assumptions and designed tools to test these assumptions.\\n\\nOn the other hand, we found probable requirements from headquarters, expecting to find\\n\\nthat a more agile approach that improved the workflow, reduced the time investment of\\n\\neveryone in the team and that both our team and the key stakeholders were very satisfied\\n\\nwith the results of the exercise and the new report.\\n\\nThe final report was slightly different from what we anticipated, but the differences were\\n\\nmore related to form and a few topics to be included in the report.\\n\\nApproach\\n\\nDespite that, the team was not used to design thinking tools, they were able to work with the\\n\\nlearning launch that was the appropriate tool. The team needs to review the insight gained\\n\\nfrom our first two launches and continuously evaluate this insight and new ones into future\\n\\nlaunch designs, especially taking into account that the full automation of the reports will take\\n\\nat least 4 years more according to the ERP implementation plan of the headquarter.\\n\\n', 'tokens': ['Reporting', 'process', '\\n\\n', 'by', 'Gilberto', 'Gamboa', '\\n\\n', 'Challenge', '\\n\\n', 'I', 'received', 'a', 'promotion', 'of', 'being', 'the', 'Regional', 'Controller', ',', 'along', 'with', 'my', 'actual', 'position', 'of', '\\n\\n', 'Country', 'CFO', '.', 'The', 'main', 'responsibility', 'of', 'this', 'new', 'position', 'was', 'to', 'weekly', 'report', 'the', 'results', '\\n\\n', 'for', 'the', 'week', 'and', 'estimate', 'the', 'final', 'results', 'of', 'the', 'month', 'of', '4', 'countries', 'and', 'consolidated', '\\n\\n', 'those', '.', '\\n\\n', 'When', 'I', 'was', 'receiving', 'the', 'position', ',', 'I', 'went', 'to', 'visit', 'my', 'colleague', ',', 'former', 'Regional', 'Controller', ',', '\\n\\n', 'who', 'was', 'promoted', 'to', 'Country', 'CEO', 'and', 'now', 'had', 'interest', 'conflicts', 'of', 'being', 'the', 'controller', '.', '\\n\\n', 'The', 'process', 'to', 'consolidate', 'the', 'information', 'of', 'the', '4', 'countries', 'was', 'that', 'the', 'country', 'controllers', '\\n\\n', 'sent', 'him', 'an', 'email', 'with', 'the', 'main', 'figures', 'for', 'the', 'week', ',', 'he', 'forwarded', 'those', 'to', 'his', 'country', '\\n\\n', 'accountant', 'who', 'consolidated', 'it', ',', 'the', 'accountant', 'sent', 'him', 'the', 'consolidated', 'report', 'and', 'he', '\\n\\n', 'finally', 'reported', 'to', 'the', 'headquarters', '.', 'The', 'whole', 'process', 'took', 'almost', 'a', 'full', 'business', 'day', 'to', '\\n\\n', 'complete', '.', '\\n\\n', 'Given', 'that', 'my', 'responsibilities', 'as', 'Country', 'CFO', 'demanded', 'more', 'attention', 'because', 'my', '\\n\\n', 'country', 'had', 'more', 'operations', ',', 'I', 'decided', 'to', 'change', 'the', 'process', 'in', 'order', 'to', 'reduce', 'the', '\\n\\n', 'duration', 'and', 'to', 'ensure', 'standardization', 'in', 'the', 'format', ',', 'and', 'actually', ',', 'reduce', 'the', 'human', '\\n\\n', 'intervention', ',', 'making', 'that', 'the', 'country', 'controllers', 'work', 'directly', 'in', 'the', 'consolidation', 'file', '.', '\\n\\n', 'Selection', '\\n\\n', 'Having', 'in', 'mind', 'that', 'there', 'was', 'a', 'different', 'kind', 'of', 'users', 'of', 'file', ',', 'I', 'select', 'some', 'of', 'those', 'to', '\\n\\n', 'determine', 'what', 'was', 'the', 'main', 'important', 'things', 'to', 'take', 'into', 'account', 'in', 'the', 'moment', 'of', 'the', '\\n\\n', 'process', 'of', 'the', 'information', 'and', 'the', 'reading', 'of', 'the', 'same', '.', 'In', 'that', 'sense', ',', 'we', 'form', 'a', 'group', 'of', '\\n\\n', 'the', 'country', 'controllers', ',', 'country', 'CEOs', ',', 'IT', 'guys', ',', 'and', 'people', 'from', 'the', 'headquarters', 'to', 'find', 'the', '\\n\\n', 'best', 'solutions', 'possible', '.', '\\n\\n', 'Application', '\\n\\n', 'For', 'the', 'first', 'lunch', ',', 'we', 'focused', 'on', 'the', 'consolidation', 'process', 'in', 'order', 'to', 'avoid', 'the', 'copy', '-', 'paste', '\\n\\n', 'processes', 'and', 'reducing', 'the', 'manual', 'intervention', 'so', ',', 'we', 'build', 'an', 'online', 'application', 'where', 'all', '\\n\\n', 'the', 'controllers', 'fill', 'the', 'figure', 'of', 'their', 'respective', 'country', ',', 'along', 'with', 'the', 'comments', '.', 'During', 'the', '\\n\\n', 'first', 'week', 'of', 'the', 'first', 'stage', ',', 'we', 'sent', 'the', 'new', 'report', 'along', 'with', 'the', 'old', 'one', ',', 'and', 'after', 'the', '\\n\\n', 'meeting', 'with', 'the', 'headquarters', 'team', ',', 'we', 'ask', 'for', 'a', 'post', '-', 'meeting', 'review', 'of', 'the', 'new', 'format', ',', 'all', '\\n\\n', 'the', 'assistants', 'provided', 'their', 'comments', 'and', 'suggestions', 'that', 'were', 'the', 'input', 'for', 'the', 'next', '\\n\\n', 'report', '.', '\\n\\n', 'For', 'the', 'second', 'lunch', ',', 'we', 'focused', 'on', 'the', 'feedback', 'received', 'from', 'the', 'assistants', 'to', 'the', 'review', '\\n\\n', 'meeting', ',', 'we', 'adjust', 'the', 'report', 'and', 'we', 'were', 'able', 'to', 'eliminate', 'the', 'old', 'one', '.', 'The', 'final', 'report', '\\n\\n', 'included', 'all', 'the', 'suggestions', 'received', 'but', 'the', 'best', 'of', 'all', 'is', 'that', 'reduced', 'the', 'time', 'investment', '\\n\\n', 'from', 'about', '36', 'men', 'hours', 'to', 'around', '8', ',', 'without', 'missing', 'any', 'valuable', 'information', 'and', '\\n\\n', 'including', 'new', 'data', 'that', 'the', 'stakeholders', 'appreciated', 'so', 'much', '.', '\\n\\n', 'Insight', '\\n\\n', 'With', 'the', 'application', 'of', 'the', 'learning', 'launch', 'tool', ',', 'the', 'controller', '’s', 'team', 'along', 'with', 'the', 'main', '\\n\\n', 'stakeholders', 'identified', 'different', 'assumptions', 'and', 'designed', 'tools', 'to', 'test', 'these', 'assumptions', '.', '\\n\\n', 'On', 'the', 'other', 'hand', ',', 'we', 'found', 'probable', 'requirements', 'from', 'headquarters', ',', 'expecting', 'to', 'find', '\\n\\n', 'that', 'a', 'more', 'agile', 'approach', 'that', 'improved', 'the', 'workflow', ',', 'reduced', 'the', 'time', 'investment', 'of', '\\n\\n', 'everyone', 'in', 'the', 'team', 'and', 'that', 'both', 'our', 'team', 'and', 'the', 'key', 'stakeholders', 'were', 'very', 'satisfied', '\\n\\n', 'with', 'the', 'results', 'of', 'the', 'exercise', 'and', 'the', 'new', 'report', '.', '\\n\\n', 'The', 'final', 'report', 'was', 'slightly', 'different', 'from', 'what', 'we', 'anticipated', ',', 'but', 'the', 'differences', 'were', '\\n\\n', 'more', 'related', 'to', 'form', 'and', 'a', 'few', 'topics', 'to', 'be', 'included', 'in', 'the', 'report', '.', '\\n\\n', 'Approach', '\\n\\n', 'Despite', 'that', ',', 'the', 'team', 'was', 'not', 'used', 'to', 'design', 'thinking', 'tools', ',', 'they', 'were', 'able', 'to', 'work', 'with', 'the', '\\n\\n', 'learning', 'launch', 'that', 'was', 'the', 'appropriate', 'tool', '.', 'The', 'team', 'needs', 'to', 'review', 'the', 'insight', 'gained', '\\n\\n', 'from', 'our', 'first', 'two', 'launches', 'and', 'continuously', 'evaluate', 'this', 'insight', 'and', 'new', 'ones', 'into', 'future', '\\n\\n', 'launch', 'designs', ',', 'especially', 'taking', 'into', 'account', 'that', 'the', 'full', 'automation', 'of', 'the', 'reports', 'will', 'take', '\\n\\n', 'at', 'least', '4', 'years', 'more', 'according', 'to', 'the', 'ERP', 'implementation', 'plan', 'of', 'the', 'headquarter', '.', '\\n\\n'], 'trailing_whitespace': [True, False, False, True, True, False, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, False, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False, True, True, False, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, False, True, True, False, False, False, False, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False], 'labels': ['O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f4d43aef084e4b93fd2d58a776e842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=2):   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6ae64ac6e841a396e0e43ebf0554d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"d:\\anaconda3\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 614, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"d:\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3446, in _map_single\n    example = apply_function_on_filtered_inputs(example, i, offset=offset)\n  File \"d:\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3349, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"<ipython-input-54-b573d538338e>\", line 14, in tokenize_and_align_labels\nIndexError: string index out of range\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ad4c44203431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmodel_save_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\cytan\\Downloads\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_max_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-ea8fa7d4a0cb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(training, training_model_path, training_max_length, path_to_datasets, model_save_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m     )\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     ds = ds.map(\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mtokenize_and_align_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mfn_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"tokenizer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"label2id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel2id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"max_length\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtraining_max_length\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m         }\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;31m# re-apply format to the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3183\u001b[0m                         \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"Map\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf\" (num_proc={num_proc})\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3184\u001b[0m                     ) as pbar:\n\u001b[1;32m-> 3185\u001b[1;33m                         for rank, done, content in iflatmap_unordered(\n\u001b[0m\u001b[0;32m   3186\u001b[0m                             \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs_per_job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3187\u001b[0m                         ):\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\datasets\\utils\\py_utils.py\u001b[0m in \u001b[0;36miflatmap_unordered\u001b[1;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpool_changed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                 \u001b[1;31m# we get the result in case there's an error to raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0masync_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0masync_result\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masync_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\datasets\\utils\\py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpool_changed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                 \u001b[1;31m# we get the result in case there's an error to raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0masync_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0masync_result\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masync_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training = True # be sure to turn internet off if doing inference\n",
    "\n",
    "    training_model_path = \"microsoft/deberta-v3-large\"\n",
    "    training_max_length = 512\n",
    "\n",
    "    # inference_model_path = \"/kaggle/input/pii-data-detection-baseline/output/checkpoint-240\" # replace with our own trained model\n",
    "    inference_model_path = r\"C:\\Users\\cytan\\Downloads\"\n",
    "    inference_max_length = 2000\n",
    "\n",
    "    # path_to_datasets = '/content/gdrive/SharedWithMe/EzKaggle2024/train.json'\n",
    "    path_to_datasets = [r'C:\\Users\\cytan\\Downloads\\pii-detection-removal-from-educational-data\\train.json'] # append path to other dataset json files to this list\n",
    "    model_save_path = r'C:\\Users\\cytan\\Downloads\\\\'\n",
    "\n",
    "    main(training, training_model_path, training_max_length, path_to_datasets, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
